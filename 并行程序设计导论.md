# 并行计算

## cpu基本概念

• socket：主板上实际插入的 cpu 硬件个数

• core：cpu的核心数，一开始，每个物理 cpu 上只有一个核心（a single core），对操作系统而言，也就是同一时刻只能运行一个进程/线程。 为了提高性能，cpu 厂商开始在单个物理 cpu 上增加核心（实实在在的硬件存在），也就出现了双核心 cpu（dual-core cpu）以及多核心 cpu（multiple cores），这样一个双核心 cpu 就是同一时刻能够运行两个进程/线程的。后来，出现了多线程技术（simultaneous multithreading，SMT，是AMD和其他CPU厂商的称呼）和超线程技术（hyper–threading，HT，Intel称呼，可以认为是SMT的一种具体技术实现）为了提高单个core同一时刻能够执行的多线程数的技术

• 查看 cpu 信息：linux 系统，lscpu

• 总的逻辑 cpu 数 = 物理 cpu 数 * 每颗物理 cpu 的核心数 * 每个核心的超线程数

## 并行计算相关概念

• 并行（parallel）、分布式（distributed）、并发（cocurrent）的区别：并发计算中，一个程序的多个任务在同一个时间段内可以同时进行，并行计算中一个程序的多个任务紧密协作来解决某个问题，更多的应用场景是多核，分布式计算中一个程序需要与其他程序协作来解决某个问题，更多的应用场景是多计算机，并行和分布式都是并发的。

• 并行计算：并行计算是相对于串行计算来说的。可分为时间上的并行和空间上的并行。 时间上的并行就是指流水线技术，而空间上的并行则是指用多个处理器并发的执行计算。并行计算的目的就是提供单处理器无法提供的性能（处理器能力或存储器），使用多处理器求解单个问题。 

• 分布式计算：分布式计算研究如何把一个需要非常巨大的计算能力才能解决的问题分成许多小的部分，然后把这些部分分配给许多计算机进行处理，最后把这些计算结果综合起来得到最终的结果。最近的分布式计算项目已经被用于使用世界各地成千上万位志愿者的计算机的闲置计算能力，通过因特网，可以分析来自外太空的电讯号，寻找隐蔽的黑洞，并探索可能存在的外星智慧生命等。 

• 并行计算与分布式计算的区别：（1）简单的理解，并行计算借助并行算法和并行编程语言能够实现进程级并行（如MPI）和线程级并行（如openMP）。而分布式计算只是将任务分成小块到各个计算机分别计算各自执行。（2）粒度方面，并行计算中，处理器间的交互一般很频繁，往往具有细粒度和低开销的特征，并且被认为是可靠的。而在分布式计算中，处理器间的交互不频繁，交互特征是粗粒度，并且被认为是不可靠的。并行计算注重短的执行时间，分布式计算则注重长的正常运行时间。（3）联系，并行计算和分布式计算两者是密切相关的。某些特征与程度（处理器间交互频率）有关，而我们还未对这种交叉点（crossover point）进行解释。另一些特征则与侧重点有关（速度与可靠性），而且我们知道这两个特性对并行和分布两类系统都很重要。（4）总之，这两种不同类型的计算在一个多维空间中代表不同但又相邻的点。 

• 集群计算：计算机集群使将一组松散集成的计算机软件和/或硬件连接起来高度紧密地协作完成计算工作。在某种意义上，他们可以被看作是一台计算机。集群系统中的单个计算机通常称为节点，通常通过局域网连接，但也有其它的可能连接方式。集群计算机通常用来改进单个计算机的计算速度和/或可靠性。一般情况下集群计算机比单个计算机，比如工作站或超级计算机性价比要高得多。根据组成集群系统的计算机之间体系结构是否相同，集群可分为同构与异构两种。集群计算机按功能和结构可以分为，高可用性集群（High-availability (HA) clusters）、负载均衡集群（Loadbalancing clusters）、高性能计算集群（High-performance (HPC)clusters）、网格计算（Grid computing）。 高可用性集群，一般是指当集群中有某个节点失效的情况下，其上的任务会自动转移到其他正常的节点上。还指可以将集群中的某节点进行离线维护再上线，该过程并不影响整个集群的运行。 

• 负载均衡集群，负载均衡集群运行时，一般通过一个或者多个前端负载均衡器，将工作负载分发到后端的一组服务器上，从而达到整个系统的高性能和高可用性。这样的计算机集群有时也被称为服务器群（Server Farm）。一般高可用性集群和负载均衡集群会使用类似的技术，或同时具有高可用性与负载均衡的特点。Linux虚拟服务器（LVS）项目在Linux操作系统上提供了最常用的负载均衡软件。 高性能计算集群，高性能计算集群采用将计算任务分配到集群的不同计算节点儿提高计算能力，因而主要应用在科学计算领域。比较流行的HPC采用Linux操作系统和其它一些免费软件来完成并行运算。这一集群配置通常被称为Beowulf集群。这类集群通常运行特定的程序以发挥HPC cluster的并行能力。这类程序一般应用特定的运行库, 比如专为科学计算设计的MPI库。HPC集群特别适合于在计算中各计算节点之间发生大量数据通讯的计算作业，比如一个节点的中间结果或影响到其它节点计算结果的情况。 

• 网格计算：网格计算是分布式计算的一种，也是一种与集群计算非常相关的技术。如果我们说某项工作是分布式的，那么，参与这项工作的一定不只是一台计算机，而是一个计算机网络，显然这种“蚂蚁搬山”的方式将具有很强的数据处理能力。网格计算的实质就是组合与共享资源并确保系统安全。网格计算通过利用大量异构计算机的未用资源（CPU周期和磁盘存储），将其作为嵌入在分布式电信基础设施中的一个虚拟的计算机集群，为解决大规模的计算问题提供一个模型。网格计算的焦点放在支持跨管理域计算的能力，这使它与传统的计算机集群或传统的分布式计算相区别。网格计算的目标是解决对于任何单一的超级计算机来说仍然大得难以解决的问题，并同时保持解决多个较小的问题的灵活性。这样，网格计算就提供了一个多用户环境。
  
## 并行硬件和软件

### 串行系统

• 冯诺依曼结构：计算机硬件的标准模型是冯诺依曼结构，由执行计算的CPU（CPU分为控制单元和算术逻辑单元ALU，CPU中的数据和程序执行时的状态存储在寄存器中），主存组成，CPU和主存之间靠总线互连。CPU与主存的分离成为冯诺依曼瓶颈。

• cache：为了突破冯诺依曼瓶颈，cahe，即CPU缓存是在CPU寄存器与主存之间的中间存储器，主要目的是降低主存访问的延迟。

• 指令集并行（ILP）使单进程可以同时执行多个指令，主要有两种ILP：流水线和多发射，对于流水线，处理器的功能单元被依次排列，其中一个的作为另一个的输入。当一个数据在第二个处理单元内成立时，另一个数据就能在第一个处理单元内处理。对于多发射，同类型的功能单元会被复制，处理器可以同时在单个程序执行多条不同的指令。

### 并行硬件

• 指令集并行和线程级并行在底层提供并行性，主要由处理器和操作系统来控制，而不是由程序员直接控制。通常利用Flynn分类法对并行硬件进行分类，冯诺依曼系统拥有单个的指令流和单个的数据流，所以单指令流单数据流（SISD）。

• 单指令流多数据流（SIMD）：在任意时间执行一条指令，但是该指令可以对多个数据项进行操作。

• 多指令流多数据流（MIMD）：系统同时执行多个指令流，每个指令流有自己的数据流。MIMD系统是多个自主处理器的集合，每个处理器可以按照自己的方式运行，不同的MIMD系统的主要区别在于是共享内存系统还是分布式内存系统，大多数MIMD是混合系统，由多个相对小的共享内存系统通过网络连接来实现，单个的共享内存系统有时称为节点。

### 并行软件

• MPI：Message-Passing Interface，消息传递接口，为分布式内存系统的编程设计，是C语言的扩展库，支持C、C++、Fortran。

• Pthreads：POSIX threads，POSIX线程，为共享内存系统的编程设计，是C语言的扩展库

• OpenMP：为共享内存系统的编程设计，包含一个扩展库以及对C编译器的部分修改，OpenMP相对于Pthreads，对C语言有更高层次的扩展，支持C、C++、Fortran。

• CUDA：NVIDIA GPU并行计算。

• Hadoop是由java语言编写的，在分布式服务器集群上存储海量数据并运行分布式分析应用的开源框架，其核心部件是HDFS与MapReduce，HDFS是一个分布式文件系统：引入存放文件元数据信息的服务器Namenode和实际存放数据的服务器Datanode，对数据进行分布式储存和读取。MapReduce是一个计算框架：MapReduce的核心思想是把计算任务分配给集群内的服务器里执行。通过对计算任务的拆分（Map计算/Reduce计算）再根据任务调度器（JobTracker）对任务进行分布式计算。

## MPI进行分布式内存编程

[配置环境](https://blog.csdn.net/renjunyang007/article/details/104970394)：win下，mingw-w64+[Microsoft MPI](https://docs.microsoft.com/en-us/message-passing-interface/microsoft-mpi-release-notes)（一共两个，在cmd里输入set MSMPI可查看安装情况）+vscode(CodeRunner+修改jason文件)